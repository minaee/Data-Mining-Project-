{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "orig:  (7070, 70)\n",
      "after set index:  (7070, 69)\n",
      "after fold differences:  (6413, 69)\n",
      "SNO A28102_at AB000114_at AB000115_at AB000220_at AB000409_at AB000449_at  \\\n",
      "1          30          22          29          76         167          32   \n",
      "2          46          31          70         208         211          20   \n",
      "3          31          20          20         244         179         229   \n",
      "4          31          20          20          39         119          20   \n",
      "5          26          26          20          85         161          34   \n",
      "..        ...         ...         ...         ...         ...         ...   \n",
      "65         68          21          35          30         131          20   \n",
      "66         77          22          30          31         132          20   \n",
      "67         56          25          65          31         158          20   \n",
      "68         41          21          32          27         164          20   \n",
      "69         38          20          25          20         172          20   \n",
      "\n",
      "SNO AB000450_at AB000460_at AB000462_at AB000464_at  ... S78825_at U11863_at  \\\n",
      "1            20         165          47         101  ...        20       155   \n",
      "2            20         184          36         130  ...        20       143   \n",
      "3            20         219          41         131  ...        20       120   \n",
      "4            20         156          26          86  ...        20       161   \n",
      "5            20         206          34         140  ...        20       119   \n",
      "..          ...         ...         ...         ...  ...       ...       ...   \n",
      "65           22         140          37          81  ...        21       106   \n",
      "66           20         150          43         128  ...        26       127   \n",
      "67           27         173          54         108  ...        20        73   \n",
      "68           20         165          74         121  ...        20        83   \n",
      "69           20         145          48         118  ...        40        94   \n",
      "\n",
      "SNO U29175_at U48730_at U58516_at X06956_at X83863_at Z17240_at M71243_f_at  \\\n",
      "1         240        27       161        34       116        44          30   \n",
      "2         213        27       265        98       123        43          31   \n",
      "3         367        24       126        21       142        44          28   \n",
      "4         358        27       163        20       134        38          21   \n",
      "5         373        41       138        29       153        42          26   \n",
      "..        ...       ...       ...       ...       ...       ...         ...   \n",
      "65        181        20       364        34       297        39          27   \n",
      "66        177        26       251        45       267        42          30   \n",
      "67        159        20       315        27       290        36          21   \n",
      "68        137        21       248        46       255        44          33   \n",
      "69        125        20       285        61       397        38          24   \n",
      "\n",
      "SNO 6413  \n",
      "1    MED  \n",
      "2    MED  \n",
      "3    MED  \n",
      "4    MED  \n",
      "5    MED  \n",
      "..   ...  \n",
      "65   JPA  \n",
      "66   JPA  \n",
      "67   JPA  \n",
      "68   JPA  \n",
      "69   JPA  \n",
      "\n",
      "[69 rows x 6414 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "\n",
    "# reading train data\n",
    "train_data = pd.read_csv('pp5i_train.gr.csv')\n",
    "print(\"orig: \", train_data.shape)\n",
    "\n",
    "\n",
    "# droping the index column\n",
    "# train_data.drop(['SNO'], axis=1, inplace=True)\n",
    "train_data.set_index(keys='SNO', inplace=True)\n",
    "print(\"after set index: \", train_data.shape)\n",
    "\n",
    "\n",
    "\n",
    "#  Threshold data\n",
    "train_data[train_data>16000] = 16000\n",
    "train_data[train_data<20] = 20\n",
    "\n",
    "\n",
    "\n",
    "# calculating and removing fold differences\n",
    "train_data['fold_differences'] = train_data.max(axis=1) / train_data.min(axis=1)\n",
    "train_data.drop(train_data[ train_data['fold_differences']<2 ].index, axis=0, inplace=True)\n",
    "train_data.drop(['fold_differences'], axis=1, inplace=True)\n",
    "print(\"after fold differences: \", train_data.shape)\n",
    "train_data.loc[len(train_data)] = \"MED\"\n",
    "\n",
    "# reading class labels and adding them to the train data\n",
    "labels = pd.read_table('pp5i_train_class.txt')\n",
    "train_data.iloc[-1, :] = labels.T.values\n",
    "# for idx, item in enumerate(train_data.iloc[-1, :]):\n",
    "#     train_data.iloc[-1, idx] = item[0]\n",
    "\n",
    "train_data = train_data.T\n",
    "\n",
    "\n",
    "\n",
    "print(train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['D50310_at', 'D55716_at', 'D78012_at', 'D80004_at', 'HG1612-HT1612_at', 'L11931_at', 'L37043_at', 'L37792_at', 'M31303_rna1_at', 'M37457_at', 'M80629_at', 'M93119_at', 'S78296_at', 'S82024_at', 'U09087_s_at', 'U16954_at', 'U18271_cds3_s_at', 'U19878_at', 'U27193_at', 'U30521_at', 'U31382_at', 'U44378_at', 'U49973_xpt2_at', 'U61145_at', 'U79248_at', 'U79262_at', 'V00599_s_at', 'X70683_at', 'X73358_s_at', 'Z69915_at']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shahriar\\AppData\\Local\\Temp/ipykernel_9816/1180999608.py:35: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  top_med.sort_index(axis=0, inplace=True, na_position='last', ascending=True)\n"
     ]
    }
   ],
   "source": [
    "med = train_data[ train_data.iloc[:, -1] == \"MED\" ]\n",
    "med = med.T\n",
    "\n",
    "med.drop(med.index[-1], inplace=True)\n",
    "# med = med.T\n",
    "\n",
    "med_inverse = train_data[ train_data.iloc[:, -1] != \"MED\"]\n",
    "med_inverse = med_inverse.T\n",
    "med_inverse.drop(med_inverse.index[-1], inplace=True)\n",
    "# med_inverse = med_inverse.T\n",
    "\n",
    "\n",
    "# print(med.shape, med_inverse.shape)\n",
    "\n",
    "med[\"mean\"] = med.mean(axis=1, skipna=True)\n",
    "med[\"std\"] = med.std(axis=1, skipna=True)\n",
    "# print(med.head(3))\n",
    "\n",
    "med_inverse[\"mean\"] = med_inverse.mean(axis=1, skipna=True)\n",
    "med_inverse[\"std\"] = med_inverse.std(axis=1, skipna=True)\n",
    "# print(med_inverse.head(3))\n",
    "\n",
    "nume = med.loc[:,'mean'] - med_inverse.loc[:,'mean']\n",
    "deno = np.sqrt( med.loc[:,'std'].pow(2)/40  + med_inverse.loc[:,'std'].pow(2)/30)\n",
    "\n",
    "med.loc[:, 'T'] = nume / deno\n",
    "\n",
    "med.drop(labels=['mean', 'std'], axis=1, inplace=True)\n",
    "\n",
    "\n",
    "med.sort_values(['T'], ascending=False, na_position='last', inplace=True)\n",
    "# med['MED'] = \"MED\"\n",
    "med.drop(labels='T', axis=1, inplace=True)\n",
    "top_med = med.iloc[:30, :]\n",
    "top_med.sort_index(axis=0, inplace=True, na_position='last', ascending=True)\n",
    "# top_med.to_csv('med.csv')\n",
    "\n",
    "med_index = list(top_med.index)\n",
    "print(med_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MGL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shahriar\\AppData\\Local\\Temp/ipykernel_9816/1697476771.py:32: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  top_mgl.sort_index(axis=0, inplace=True, na_position='last', ascending=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['D17716_at',\n",
       " 'D85815_at',\n",
       " 'D87023_cds2_at',\n",
       " 'HG1804-HT1829_at',\n",
       " 'HG3286-HT3463_at',\n",
       " 'HG4490-HT4876_f_at',\n",
       " 'HG881-HT881_at',\n",
       " 'J05500_at',\n",
       " 'L05628_s_at',\n",
       " 'L25270_at',\n",
       " 'L34355_at',\n",
       " 'L36463_at',\n",
       " 'L41351_at',\n",
       " 'L42354_at',\n",
       " 'L43338_at',\n",
       " 'M20137_at',\n",
       " 'M83308_at',\n",
       " 'S83362_s_at',\n",
       " 'U17760_rna1_at',\n",
       " 'U52155_at',\n",
       " 'U70321_at',\n",
       " 'U78551_at',\n",
       " 'V01515_cds1_at',\n",
       " 'X00371_rna1_at',\n",
       " 'X03066_at',\n",
       " 'X07730_at',\n",
       " 'X14329_at',\n",
       " 'X52011_at',\n",
       " 'X52425_at',\n",
       " 'X96401_at']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mgl = train_data[ train_data.iloc[:, -1] == \"MGL\" ]\n",
    "mgl = mgl.T\n",
    "mgl.drop(mgl.index[-1], inplace=True)\n",
    "# mgl = mgl.T\n",
    "\n",
    "mgl_inverse = train_data[ train_data.iloc[:, -1] != \"MGL\"]\n",
    "mgl_inverse = mgl_inverse.T\n",
    "mgl_inverse.drop(mgl_inverse.index[-1], inplace=True)\n",
    "# mgl_inverse = mgl_inverse.T\n",
    "\n",
    "# print(mgl.shape, mgl_inverse.shape)\n",
    "\n",
    "mgl[\"mean\"] = mgl.mean(axis=1, skipna=True)\n",
    "mgl[\"std\"] = mgl.std(axis=1, skipna=True)\n",
    "# print(mgl.head(3))\n",
    "\n",
    "mgl_inverse[\"mean\"] = mgl_inverse.mean(axis=1, skipna=True)\n",
    "mgl_inverse[\"std\"] = mgl_inverse.std(axis=1, skipna=True)\n",
    "# print(mgl_inverse.head(3))\n",
    "\n",
    "\n",
    "nume = mgl.loc[:,'mean'] - mgl_inverse.loc[:,'mean']\n",
    "deno = np.sqrt( mgl.loc[:,'std'].pow(2)/7  + mgl_inverse.loc[:,'std'].pow(2)/63)\n",
    "\n",
    "mgl.loc[:, 'T'] = nume / deno\n",
    "\n",
    "mgl.drop(labels=['mean', 'std'], axis=1, inplace=True)\n",
    "mgl.sort_values(['T'], ascending=False, na_position='last', inplace=True)\n",
    "# mgl['MGL'] = \"MGL\"\n",
    "mgl.drop(labels='T', axis=1, inplace=True)\n",
    "top_mgl = mgl.iloc[:30, :]\n",
    "top_mgl.sort_index(axis=0, inplace=True, na_position='last', ascending=True)\n",
    "# top_mgl.to_csv('mgl.csv')\n",
    "mgl_index = list(top_mgl.index)\n",
    "mgl_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RHB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shahriar\\AppData\\Local\\Temp/ipykernel_9816/2656548043.py:31: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  top_rhb.sort_index(axis=0, inplace=True, na_position='last', ascending=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['AJ001421_at',\n",
       " 'D14043_at',\n",
       " 'D29675_s_at',\n",
       " 'D31766_at',\n",
       " 'D31890_at',\n",
       " 'D42041_at',\n",
       " 'D45248_at',\n",
       " 'D50405_at',\n",
       " 'D79997_at',\n",
       " 'D83174_s_at',\n",
       " 'HG1595-HT4788_s_at',\n",
       " 'HG3514-HT3708_at',\n",
       " 'HG613-HT613_at',\n",
       " 'J03191_at',\n",
       " 'L06132_at',\n",
       " 'L23333_s_at',\n",
       " 'M34338_s_at',\n",
       " 'M57464_s_at',\n",
       " 'M96954_s_at',\n",
       " 'U33818_at',\n",
       " 'U47621_at',\n",
       " 'U96131_at',\n",
       " 'X04106_at',\n",
       " 'X15187_at',\n",
       " 'X54304_at',\n",
       " 'X57959_at',\n",
       " 'X63469_at',\n",
       " 'X68090_s_at',\n",
       " 'Y07604_at',\n",
       " 'Z97074_at']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "rhb = train_data[ train_data.iloc[:, -1] == \"RHB\" ]\n",
    "rhb = rhb.T\n",
    "rhb.drop(rhb.index[-1], inplace=True)\n",
    "# rhb = rhb.T\n",
    "\n",
    "rhb_inverse = train_data[ train_data.iloc[:, -1] != \"RHB\"]\n",
    "rhb_inverse = rhb_inverse.T\n",
    "rhb_inverse.drop(rhb_inverse.index[-1], inplace=True)\n",
    "# rhb_inverse = rhb_inverse.T\n",
    "\n",
    "# print(rhb.shape, rhb_inverse.shape)\n",
    "\n",
    "rhb[\"mean\"] = rhb.mean(axis=1, skipna=True)\n",
    "rhb[\"std\"] = rhb.std(axis=1, skipna=True)\n",
    "# print(rhb.head(3))\n",
    "\n",
    "rhb_inverse[\"mean\"] = rhb_inverse.mean(axis=1, skipna=True)\n",
    "rhb_inverse[\"std\"] = rhb_inverse.std(axis=1, skipna=True)\n",
    "# print(rhb_inverse.head(3))\n",
    "\n",
    "nume = rhb.loc[:,'mean'] - rhb_inverse.loc[:,'mean']\n",
    "deno = np.sqrt( rhb.loc[:,'std'].pow(2)/7  + rhb_inverse.loc[:,'std'].pow(2)/63)\n",
    "\n",
    "rhb.loc[:, 'T'] = nume / deno\n",
    "rhb.drop(labels=['mean', 'std'], axis=1, inplace=True)\n",
    "\n",
    "rhb.sort_values(['T'], ascending=False, na_position='last', inplace=True)\n",
    "# rhb['RHB'] = \"RHB\"\n",
    "rhb.drop(labels='T', axis=1, inplace=True)\n",
    "top_rhb = rhb.iloc[:30, :]\n",
    "top_rhb.sort_index(axis=0, inplace=True, na_position='last', ascending=True)\n",
    "# top_rhb.to_csv('rhb.csv')\n",
    "rhb_index = list(top_rhb.index)\n",
    "rhb_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shahriar\\AppData\\Local\\Temp/ipykernel_9816/4080769117.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  top_epd.sort_index(axis=0, inplace=True, na_position='last', ascending=True)\n"
     ]
    }
   ],
   "source": [
    "epd = train_data[ train_data.iloc[:, -1] == \"EPD\" ]\n",
    "epd = epd.T\n",
    "epd.drop(epd.index[-1], inplace=True)\n",
    "# epd = epd.T\n",
    "\n",
    "epd_inverse = train_data[ train_data.iloc[:, -1] != \"EPD\"]\n",
    "epd_inverse = epd_inverse.T\n",
    "epd_inverse.drop(epd_inverse.index[-1], inplace=True)\n",
    "# epd_inverse = epd_inverse.T\n",
    "\n",
    "# print(epd.shape, epd_inverse.shape)\n",
    "\n",
    "epd[\"mean\"] = epd.mean(axis=1, skipna=True)\n",
    "epd[\"std\"] = epd.std(axis=1, skipna=True)\n",
    "# print(epd.head(3))\n",
    "\n",
    "epd_inverse[\"mean\"] = epd_inverse.mean(axis=1, skipna=True)\n",
    "epd_inverse[\"std\"] = epd_inverse.std(axis=1, skipna=True)\n",
    "# print(epd_inverse.head(3))\n",
    "\n",
    "nume = epd.loc[:,'mean'] - epd_inverse.loc[:,'mean']\n",
    "deno = np.sqrt( epd.loc[:,'std'].pow(2)/10  + epd_inverse.loc[:,'std'].pow(2)/60)\n",
    "\n",
    "epd.loc[:, 'T'] = nume / deno\n",
    "epd.drop(labels=['mean', 'std'], axis=1, inplace=True)\n",
    "epd.sort_values(['T'], ascending=False, na_position='last', inplace=True)\n",
    "# epd['EPD'] = \"EPD\"\n",
    "epd.drop(labels='T', axis=1, inplace=True)\n",
    "top_epd = epd.iloc[:30, :]\n",
    "top_epd.sort_index(axis=0, inplace=True, na_position='last', ascending=True)\n",
    "# top_epd.to_csv('epd.csv')\n",
    "epd_index = list(top_epd.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6413, 6) (6413, 63)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shahriar\\AppData\\Local\\Temp/ipykernel_9816/3164216440.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  top_jpa.sort_index(axis=0, inplace=True, na_position='last', ascending=True)\n"
     ]
    }
   ],
   "source": [
    "jpa = train_data[ train_data.iloc[:, -1] == \"JPA\" ]\n",
    "jpa = jpa.T\n",
    "jpa.drop(jpa.index[-1], inplace=True)\n",
    "# jpa = jpa.T\n",
    "\n",
    "jpa_inverse = train_data[ train_data.iloc[:, -1] != \"JPA\"]\n",
    "jpa_inverse = jpa_inverse.T\n",
    "jpa_inverse.drop(jpa_inverse.index[-1], inplace=True)\n",
    "# jpa_inverse = jpa_inverse.T\n",
    "\n",
    "print(jpa.shape, jpa_inverse.shape)\n",
    "\n",
    "jpa[\"mean\"] = jpa.mean(axis=1, skipna=True)\n",
    "jpa[\"std\"] = jpa.std(axis=1, skipna=True)\n",
    "# print(jpa.head(3))\n",
    "\n",
    "jpa_inverse[\"mean\"] = jpa_inverse.mean(axis=1, skipna=True)\n",
    "jpa_inverse[\"std\"] = jpa_inverse.std(axis=1, skipna=True)\n",
    "# print(jpa_inverse.head(3))\n",
    "\n",
    "nume = jpa.loc[:,'mean'] - jpa_inverse.loc[:,'mean']\n",
    "deno = np.sqrt( jpa.loc[:,'std'].pow(2)/6  + jpa_inverse.loc[:,'std'].pow(2)/64)\n",
    "\n",
    "jpa.loc[:, 'T'] = nume / deno\n",
    "jpa.drop(labels=['mean', 'std'], axis=1, inplace=True)\n",
    "jpa.sort_values(['T'], ascending=False, na_position='last', inplace=True)\n",
    "# jpa['JPA'] = \"JPA\"\n",
    "jpa.drop(labels='T', axis=1, inplace=True)\n",
    "top_jpa = jpa.iloc[:30, :]\n",
    "top_jpa.sort_index(axis=0, inplace=True, na_position='last', ascending=True)\n",
    "# top_jpa.to_csv('jpa.csv')\n",
    "jpa_index = list(top_jpa.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150\n",
      "['M31303_rna1_at', 'X03663_at', 'S83362_s_at', 'U68142_at', 'M83308_at', 'M20137_at', 'M75099_at', 'U47621_at', 'U31382_at', 'J05500_at', 'D55716_at', 'U78551_at', 'M84349_at', 'X14813_at', 'D63506_at', 'S82024_at', 'U30521_at', 'M34057_at', 'U91930_at', 'D87023_cds2_at', 'X14329_at', 'U17760_rna1_at', 'X52425_at', 'U79294_at', 'U79254_at', 'U90552_s_at', 'L11931_at', 'HG3514-HT3708_at', 'M37457_at', 'Z97074_at', 'X75861_at', 'D79996_at', 'L08895_at', 'X04106_at', 'L42354_at', 'M80629_at', 'X15187_at', 'U51336_at', 'L36818_at', 'HG3286-HT3463_at', 'L18960_at', 'U47101_at', 'D42041_at', 'M16447_at', 'HG4490-HT4876_f_at', 'D85815_at', 'X60188_at', 'L37792_at', 'J04543_at', 'U65410_at', 'Z56281_at', 'U06155_at', 'D14043_at', 'L05628_s_at', 'U27193_at', 'X78706_at', 'U90916_at', 'L42572_at', 'X03066_at', 'V01515_cds1_at', 'U18271_cds3_s_at', 'D31766_at', 'HG613-HT613_at', 'U52155_at', 'D45248_at', 'U79267_at', 'X68090_s_at', 'U79262_at', 'X73358_s_at', 'U96131_at', 'D50310_at', 'L23333_s_at', 'D50405_at', 'D80004_at', 'L36463_at', 'L43338_at', 'Z19554_s_at', 'Y07604_at', 'S78296_at', 'D31767_at', 'U46692_rna1_at', 'U01923_at', 'M59488_at', 'D87470_at', 'U61145_at', 'U09087_s_at', 'D13631_s_at', 'X61587_at', 'D17716_at', 'U48705_rna1_s_at', 'M63838_s_at', 'D31890_at', 'X07730_at', 'X70683_at', 'U19878_at', 'AJ001421_at', 'X99720_rna1_at', 'X57959_at', 'Z29064_at', 'M23161_at', 'X76105_at', 'D00763_at', 'U70321_at', 'U49973_xpt2_at', 'U79248_at', 'U32331_at', 'X54304_at', 'M93426_at', 'M93119_at', 'L37043_at', 'U16954_at', 'Z69915_at', 'X65784_s_at', 'J03191_at', 'U44378_at', 'S79873_s_at', 'HG1612-HT1612_at', 'U24266_at', 'D83174_s_at', 'M69066_at', 'M34338_s_at', 'U33818_at', 'U07550_at', 'HG881-HT881_at', 'D29675_s_at', 'V00599_s_at', 'X03363_s_at', 'U32114_at', 'X52011_at', 'D25304_at', 'L06132_at', 'D78012_at', 'HG1804-HT1829_at', 'X84195_at', 'M19645_at', 'HG1595-HT4788_s_at', 'X63469_at', 'X96401_at', 'U52828_s_at', 'D14662_at', 'M94151_at', 'U83463_at', 'L25270_at', 'M57464_s_at', 'L34355_at', 'U66879_at', 'L41351_at', 'M96954_s_at', 'D79997_at', 'X00371_rna1_at']\n"
     ]
    }
   ],
   "source": [
    "indexes = list(med_index)\n",
    "for item in mgl_index:\n",
    "    indexes.append(item)\n",
    "for item in epd_index:\n",
    "    indexes.append(item)\n",
    "for item in jpa_index:\n",
    "    indexes.append(item)\n",
    "for item in rhb_index:\n",
    "    indexes.append(item)\n",
    "print(len(indexes))\n",
    "\n",
    "indexes = list(set(indexes))\n",
    "print((indexes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shahriar\\AppData\\Local\\Temp/ipykernel_9816/3287627526.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[[item]] = train_data[[item]]\n",
      "C:\\Users\\Shahriar\\AppData\\Local\\Temp/ipykernel_9816/3287627526.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[[item]] = train_data[[item]]\n",
      "C:\\Users\\Shahriar\\AppData\\Local\\Temp/ipykernel_9816/3287627526.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[[item]] = train_data[[item]]\n",
      "C:\\Users\\Shahriar\\AppData\\Local\\Temp/ipykernel_9816/3287627526.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[[item]] = train_data[[item]]\n",
      "C:\\Users\\Shahriar\\AppData\\Local\\Temp/ipykernel_9816/3287627526.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[[item]] = train_data[[item]]\n",
      "C:\\Users\\Shahriar\\AppData\\Local\\Temp/ipykernel_9816/3287627526.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[[item]] = train_data[[item]]\n",
      "C:\\Users\\Shahriar\\AppData\\Local\\Temp/ipykernel_9816/3287627526.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[[item]] = train_data[[item]]\n",
      "C:\\Users\\Shahriar\\AppData\\Local\\Temp/ipykernel_9816/3287627526.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[[item]] = train_data[[item]]\n",
      "C:\\Users\\Shahriar\\AppData\\Local\\Temp/ipykernel_9816/3287627526.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[[item]] = train_data[[item]]\n",
      "C:\\Users\\Shahriar\\AppData\\Local\\Temp/ipykernel_9816/3287627526.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[[item]] = train_data[[item]]\n",
      "C:\\Users\\Shahriar\\AppData\\Local\\Temp/ipykernel_9816/3287627526.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[[item]] = train_data[[item]]\n",
      "C:\\Users\\Shahriar\\AppData\\Local\\Temp/ipykernel_9816/3287627526.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[[item]] = train_data[[item]]\n",
      "C:\\Users\\Shahriar\\AppData\\Local\\Temp/ipykernel_9816/3287627526.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[[item]] = train_data[[item]]\n",
      "C:\\Users\\Shahriar\\AppData\\Local\\Temp/ipykernel_9816/3287627526.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[[item]] = train_data[[item]]\n",
      "C:\\Users\\Shahriar\\AppData\\Local\\Temp/ipykernel_9816/3287627526.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[[item]] = train_data[[item]]\n",
      "C:\\Users\\Shahriar\\AppData\\Local\\Temp/ipykernel_9816/3287627526.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[[item]] = train_data[[item]]\n",
      "C:\\Users\\Shahriar\\AppData\\Local\\Temp/ipykernel_9816/3287627526.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[[item]] = train_data[[item]]\n",
      "C:\\Users\\Shahriar\\AppData\\Local\\Temp/ipykernel_9816/3287627526.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[[item]] = train_data[[item]]\n",
      "C:\\Users\\Shahriar\\AppData\\Local\\Temp/ipykernel_9816/3287627526.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[[item]] = train_data[[item]]\n",
      "C:\\Users\\Shahriar\\AppData\\Local\\Temp/ipykernel_9816/3287627526.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[[item]] = train_data[[item]]\n",
      "C:\\Users\\Shahriar\\AppData\\Local\\Temp/ipykernel_9816/3287627526.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[[item]] = train_data[[item]]\n",
      "C:\\Users\\Shahriar\\AppData\\Local\\Temp/ipykernel_9816/3287627526.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[[item]] = train_data[[item]]\n",
      "C:\\Users\\Shahriar\\AppData\\Local\\Temp/ipykernel_9816/3287627526.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[[item]] = train_data[[item]]\n",
      "C:\\Users\\Shahriar\\AppData\\Local\\Temp/ipykernel_9816/3287627526.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[[item]] = train_data[[item]]\n",
      "C:\\Users\\Shahriar\\AppData\\Local\\Temp/ipykernel_9816/3287627526.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[[item]] = train_data[[item]]\n",
      "C:\\Users\\Shahriar\\AppData\\Local\\Temp/ipykernel_9816/3287627526.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[[item]] = train_data[[item]]\n",
      "C:\\Users\\Shahriar\\AppData\\Local\\Temp/ipykernel_9816/3287627526.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[[item]] = train_data[[item]]\n",
      "C:\\Users\\Shahriar\\AppData\\Local\\Temp/ipykernel_9816/3287627526.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[[item]] = train_data[[item]]\n",
      "C:\\Users\\Shahriar\\AppData\\Local\\Temp/ipykernel_9816/3287627526.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[[item]] = train_data[[item]]\n",
      "C:\\Users\\Shahriar\\AppData\\Local\\Temp/ipykernel_9816/3287627526.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[[item]] = train_data[[item]]\n",
      "C:\\Users\\Shahriar\\AppData\\Local\\Temp/ipykernel_9816/3287627526.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[[item]] = train_data[[item]]\n",
      "C:\\Users\\Shahriar\\AppData\\Local\\Temp/ipykernel_9816/3287627526.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[[item]] = train_data[[item]]\n",
      "C:\\Users\\Shahriar\\AppData\\Local\\Temp/ipykernel_9816/3287627526.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[[item]] = train_data[[item]]\n",
      "C:\\Users\\Shahriar\\AppData\\Local\\Temp/ipykernel_9816/3287627526.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[[item]] = train_data[[item]]\n",
      "C:\\Users\\Shahriar\\AppData\\Local\\Temp/ipykernel_9816/3287627526.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[[item]] = train_data[[item]]\n",
      "C:\\Users\\Shahriar\\AppData\\Local\\Temp/ipykernel_9816/3287627526.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[[item]] = train_data[[item]]\n",
      "C:\\Users\\Shahriar\\AppData\\Local\\Temp/ipykernel_9816/3287627526.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[[item]] = train_data[[item]]\n",
      "C:\\Users\\Shahriar\\AppData\\Local\\Temp/ipykernel_9816/3287627526.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[[item]] = train_data[[item]]\n",
      "C:\\Users\\Shahriar\\AppData\\Local\\Temp/ipykernel_9816/3287627526.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[[item]] = train_data[[item]]\n",
      "C:\\Users\\Shahriar\\AppData\\Local\\Temp/ipykernel_9816/3287627526.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[[item]] = train_data[[item]]\n",
      "C:\\Users\\Shahriar\\AppData\\Local\\Temp/ipykernel_9816/3287627526.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[[item]] = train_data[[item]]\n",
      "C:\\Users\\Shahriar\\AppData\\Local\\Temp/ipykernel_9816/3287627526.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[[item]] = train_data[[item]]\n",
      "C:\\Users\\Shahriar\\AppData\\Local\\Temp/ipykernel_9816/3287627526.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[[item]] = train_data[[item]]\n",
      "C:\\Users\\Shahriar\\AppData\\Local\\Temp/ipykernel_9816/3287627526.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[[item]] = train_data[[item]]\n",
      "C:\\Users\\Shahriar\\AppData\\Local\\Temp/ipykernel_9816/3287627526.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[[item]] = train_data[[item]]\n",
      "C:\\Users\\Shahriar\\AppData\\Local\\Temp/ipykernel_9816/3287627526.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[[item]] = train_data[[item]]\n",
      "C:\\Users\\Shahriar\\AppData\\Local\\Temp/ipykernel_9816/3287627526.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[[item]] = train_data[[item]]\n",
      "C:\\Users\\Shahriar\\AppData\\Local\\Temp/ipykernel_9816/3287627526.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[[item]] = train_data[[item]]\n",
      "C:\\Users\\Shahriar\\AppData\\Local\\Temp/ipykernel_9816/3287627526.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[[item]] = train_data[[item]]\n",
      "C:\\Users\\Shahriar\\AppData\\Local\\Temp/ipykernel_9816/3287627526.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[[item]] = train_data[[item]]\n",
      "C:\\Users\\Shahriar\\AppData\\Local\\Temp/ipykernel_9816/3287627526.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['class'] = train_data.iloc[:, -1]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>M31303_rna1_at</th>\n",
       "      <th>X03663_at</th>\n",
       "      <th>S83362_s_at</th>\n",
       "      <th>U68142_at</th>\n",
       "      <th>M83308_at</th>\n",
       "      <th>M20137_at</th>\n",
       "      <th>M75099_at</th>\n",
       "      <th>U47621_at</th>\n",
       "      <th>U31382_at</th>\n",
       "      <th>J05500_at</th>\n",
       "      <th>...</th>\n",
       "      <th>U83463_at</th>\n",
       "      <th>L25270_at</th>\n",
       "      <th>M57464_s_at</th>\n",
       "      <th>L34355_at</th>\n",
       "      <th>U66879_at</th>\n",
       "      <th>L41351_at</th>\n",
       "      <th>M96954_s_at</th>\n",
       "      <th>D79997_at</th>\n",
       "      <th>X00371_rna1_at</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>724</td>\n",
       "      <td>29</td>\n",
       "      <td>69</td>\n",
       "      <td>126</td>\n",
       "      <td>198</td>\n",
       "      <td>117</td>\n",
       "      <td>96</td>\n",
       "      <td>68</td>\n",
       "      <td>332</td>\n",
       "      <td>93</td>\n",
       "      <td>...</td>\n",
       "      <td>229</td>\n",
       "      <td>22</td>\n",
       "      <td>293</td>\n",
       "      <td>62</td>\n",
       "      <td>83</td>\n",
       "      <td>73</td>\n",
       "      <td>196</td>\n",
       "      <td>43</td>\n",
       "      <td>29</td>\n",
       "      <td>MED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>579</td>\n",
       "      <td>56</td>\n",
       "      <td>66</td>\n",
       "      <td>136</td>\n",
       "      <td>180</td>\n",
       "      <td>75</td>\n",
       "      <td>139</td>\n",
       "      <td>33</td>\n",
       "      <td>165</td>\n",
       "      <td>83</td>\n",
       "      <td>...</td>\n",
       "      <td>240</td>\n",
       "      <td>21</td>\n",
       "      <td>192</td>\n",
       "      <td>64</td>\n",
       "      <td>20</td>\n",
       "      <td>53</td>\n",
       "      <td>215</td>\n",
       "      <td>38</td>\n",
       "      <td>20</td>\n",
       "      <td>MED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>608</td>\n",
       "      <td>20</td>\n",
       "      <td>63</td>\n",
       "      <td>233</td>\n",
       "      <td>157</td>\n",
       "      <td>68</td>\n",
       "      <td>184</td>\n",
       "      <td>20</td>\n",
       "      <td>183</td>\n",
       "      <td>78</td>\n",
       "      <td>...</td>\n",
       "      <td>145</td>\n",
       "      <td>22</td>\n",
       "      <td>73</td>\n",
       "      <td>61</td>\n",
       "      <td>51</td>\n",
       "      <td>62</td>\n",
       "      <td>163</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>MED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>619</td>\n",
       "      <td>20</td>\n",
       "      <td>64</td>\n",
       "      <td>137</td>\n",
       "      <td>146</td>\n",
       "      <td>101</td>\n",
       "      <td>181</td>\n",
       "      <td>46</td>\n",
       "      <td>152</td>\n",
       "      <td>75</td>\n",
       "      <td>...</td>\n",
       "      <td>271</td>\n",
       "      <td>21</td>\n",
       "      <td>111</td>\n",
       "      <td>64</td>\n",
       "      <td>98</td>\n",
       "      <td>58</td>\n",
       "      <td>130</td>\n",
       "      <td>103</td>\n",
       "      <td>28</td>\n",
       "      <td>MED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>676</td>\n",
       "      <td>20</td>\n",
       "      <td>71</td>\n",
       "      <td>258</td>\n",
       "      <td>146</td>\n",
       "      <td>83</td>\n",
       "      <td>113</td>\n",
       "      <td>20</td>\n",
       "      <td>105</td>\n",
       "      <td>78</td>\n",
       "      <td>...</td>\n",
       "      <td>92</td>\n",
       "      <td>25</td>\n",
       "      <td>32</td>\n",
       "      <td>66</td>\n",
       "      <td>46</td>\n",
       "      <td>59</td>\n",
       "      <td>113</td>\n",
       "      <td>45</td>\n",
       "      <td>33</td>\n",
       "      <td>MED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>343</td>\n",
       "      <td>243</td>\n",
       "      <td>60</td>\n",
       "      <td>198</td>\n",
       "      <td>195</td>\n",
       "      <td>95</td>\n",
       "      <td>238</td>\n",
       "      <td>27</td>\n",
       "      <td>32</td>\n",
       "      <td>66</td>\n",
       "      <td>...</td>\n",
       "      <td>337</td>\n",
       "      <td>20</td>\n",
       "      <td>62</td>\n",
       "      <td>91</td>\n",
       "      <td>47</td>\n",
       "      <td>46</td>\n",
       "      <td>149</td>\n",
       "      <td>20</td>\n",
       "      <td>35</td>\n",
       "      <td>JPA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>277</td>\n",
       "      <td>205</td>\n",
       "      <td>66</td>\n",
       "      <td>172</td>\n",
       "      <td>210</td>\n",
       "      <td>118</td>\n",
       "      <td>230</td>\n",
       "      <td>20</td>\n",
       "      <td>40</td>\n",
       "      <td>82</td>\n",
       "      <td>...</td>\n",
       "      <td>339</td>\n",
       "      <td>23</td>\n",
       "      <td>66</td>\n",
       "      <td>98</td>\n",
       "      <td>22</td>\n",
       "      <td>46</td>\n",
       "      <td>146</td>\n",
       "      <td>20</td>\n",
       "      <td>43</td>\n",
       "      <td>JPA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>256</td>\n",
       "      <td>176</td>\n",
       "      <td>56</td>\n",
       "      <td>188</td>\n",
       "      <td>239</td>\n",
       "      <td>111</td>\n",
       "      <td>231</td>\n",
       "      <td>37</td>\n",
       "      <td>48</td>\n",
       "      <td>69</td>\n",
       "      <td>...</td>\n",
       "      <td>361</td>\n",
       "      <td>20</td>\n",
       "      <td>83</td>\n",
       "      <td>84</td>\n",
       "      <td>52</td>\n",
       "      <td>49</td>\n",
       "      <td>140</td>\n",
       "      <td>20</td>\n",
       "      <td>31</td>\n",
       "      <td>JPA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>271</td>\n",
       "      <td>242</td>\n",
       "      <td>74</td>\n",
       "      <td>217</td>\n",
       "      <td>251</td>\n",
       "      <td>101</td>\n",
       "      <td>216</td>\n",
       "      <td>20</td>\n",
       "      <td>23</td>\n",
       "      <td>84</td>\n",
       "      <td>...</td>\n",
       "      <td>337</td>\n",
       "      <td>24</td>\n",
       "      <td>75</td>\n",
       "      <td>86</td>\n",
       "      <td>20</td>\n",
       "      <td>64</td>\n",
       "      <td>125</td>\n",
       "      <td>20</td>\n",
       "      <td>33</td>\n",
       "      <td>JPA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>228</td>\n",
       "      <td>205</td>\n",
       "      <td>63</td>\n",
       "      <td>198</td>\n",
       "      <td>272</td>\n",
       "      <td>121</td>\n",
       "      <td>248</td>\n",
       "      <td>20</td>\n",
       "      <td>28</td>\n",
       "      <td>81</td>\n",
       "      <td>...</td>\n",
       "      <td>371</td>\n",
       "      <td>20</td>\n",
       "      <td>65</td>\n",
       "      <td>118</td>\n",
       "      <td>48</td>\n",
       "      <td>45</td>\n",
       "      <td>108</td>\n",
       "      <td>20</td>\n",
       "      <td>39</td>\n",
       "      <td>JPA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>69 rows  151 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   M31303_rna1_at X03663_at S83362_s_at U68142_at M83308_at M20137_at  \\\n",
       "1             724        29          69       126       198       117   \n",
       "2             579        56          66       136       180        75   \n",
       "3             608        20          63       233       157        68   \n",
       "4             619        20          64       137       146       101   \n",
       "5             676        20          71       258       146        83   \n",
       "..            ...       ...         ...       ...       ...       ...   \n",
       "65            343       243          60       198       195        95   \n",
       "66            277       205          66       172       210       118   \n",
       "67            256       176          56       188       239       111   \n",
       "68            271       242          74       217       251       101   \n",
       "69            228       205          63       198       272       121   \n",
       "\n",
       "   M75099_at U47621_at U31382_at J05500_at  ... U83463_at L25270_at  \\\n",
       "1         96        68       332        93  ...       229        22   \n",
       "2        139        33       165        83  ...       240        21   \n",
       "3        184        20       183        78  ...       145        22   \n",
       "4        181        46       152        75  ...       271        21   \n",
       "5        113        20       105        78  ...        92        25   \n",
       "..       ...       ...       ...       ...  ...       ...       ...   \n",
       "65       238        27        32        66  ...       337        20   \n",
       "66       230        20        40        82  ...       339        23   \n",
       "67       231        37        48        69  ...       361        20   \n",
       "68       216        20        23        84  ...       337        24   \n",
       "69       248        20        28        81  ...       371        20   \n",
       "\n",
       "   M57464_s_at L34355_at U66879_at L41351_at M96954_s_at D79997_at  \\\n",
       "1          293        62        83        73         196        43   \n",
       "2          192        64        20        53         215        38   \n",
       "3           73        61        51        62         163        20   \n",
       "4          111        64        98        58         130       103   \n",
       "5           32        66        46        59         113        45   \n",
       "..         ...       ...       ...       ...         ...       ...   \n",
       "65          62        91        47        46         149        20   \n",
       "66          66        98        22        46         146        20   \n",
       "67          83        84        52        49         140        20   \n",
       "68          75        86        20        64         125        20   \n",
       "69          65       118        48        45         108        20   \n",
       "\n",
       "   X00371_rna1_at class  \n",
       "1              29   MED  \n",
       "2              20   MED  \n",
       "3              20   MED  \n",
       "4              28   MED  \n",
       "5              33   MED  \n",
       "..            ...   ...  \n",
       "65             35   JPA  \n",
       "66             43   JPA  \n",
       "67             31   JPA  \n",
       "68             33   JPA  \n",
       "69             39   JPA  \n",
       "\n",
       "[69 rows x 151 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.DataFrame()\n",
    "for item in indexes:\n",
    "    data[[item]] = train_data[[item]]\n",
    "data['class'] = train_data.iloc[:, -1]\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('pp5i_train.topN.gr.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(69, 151) \n",
      "     M31303_rna1_at  X03663_at  S83362_s_at  U68142_at  M83308_at  M20137_at  \\\n",
      "0              724         29           69        126        198        117   \n",
      "1              579         56           66        136        180         75   \n",
      "2              608         20           63        233        157         68   \n",
      "3              619         20           64        137        146        101   \n",
      "4              676         20           71        258        146         83   \n",
      "..             ...        ...          ...        ...        ...        ...   \n",
      "64             343        243           60        198        195         95   \n",
      "65             277        205           66        172        210        118   \n",
      "66             256        176           56        188        239        111   \n",
      "67             271        242           74        217        251        101   \n",
      "68             228        205           63        198        272        121   \n",
      "\n",
      "    M75099_at  U47621_at  U31382_at  J05500_at  ...  U83463_at  L25270_at  \\\n",
      "0          96         68        332         93  ...        229         22   \n",
      "1         139         33        165         83  ...        240         21   \n",
      "2         184         20        183         78  ...        145         22   \n",
      "3         181         46        152         75  ...        271         21   \n",
      "4         113         20        105         78  ...         92         25   \n",
      "..        ...        ...        ...        ...  ...        ...        ...   \n",
      "64        238         27         32         66  ...        337         20   \n",
      "65        230         20         40         82  ...        339         23   \n",
      "66        231         37         48         69  ...        361         20   \n",
      "67        216         20         23         84  ...        337         24   \n",
      "68        248         20         28         81  ...        371         20   \n",
      "\n",
      "    M57464_s_at  L34355_at  U66879_at  L41351_at  M96954_s_at  D79997_at  \\\n",
      "0           293         62         83         73          196         43   \n",
      "1           192         64         20         53          215         38   \n",
      "2            73         61         51         62          163         20   \n",
      "3           111         64         98         58          130        103   \n",
      "4            32         66         46         59          113         45   \n",
      "..          ...        ...        ...        ...          ...        ...   \n",
      "64           62         91         47         46          149         20   \n",
      "65           66         98         22         46          146         20   \n",
      "66           83         84         52         49          140         20   \n",
      "67           75         86         20         64          125         20   \n",
      "68           65        118         48         45          108         20   \n",
      "\n",
      "    X00371_rna1_at  class  \n",
      "0               29    MED  \n",
      "1               20    MED  \n",
      "2               20    MED  \n",
      "3               28    MED  \n",
      "4               33    MED  \n",
      "..             ...    ...  \n",
      "64              35    JPA  \n",
      "65              43    JPA  \n",
      "66              31    JPA  \n",
      "67              33    JPA  \n",
      "68              39    JPA  \n",
      "\n",
      "[69 rows x 151 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "\n",
    "\n",
    "train = pd.read_csv('pp5i_train.topN.gr.csv')\n",
    "\n",
    "train.drop(labels=['Unnamed: 0'], axis=1, inplace=True)\n",
    "print(train.shape, \"\\n\", train )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\python\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5142857142857142"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "\n",
    "X, y = train.iloc[:, :train.shape[1]-1], train[['class']]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=0)\n",
    "gnb = GaussianNB()\n",
    "gnb.fit(X_train, y_train)\n",
    "\n",
    "y_pred = gnb.predict(X_test)\n",
    "# print(\"Number of mislabeled points out of a total %d points : %d\"\n",
    "#       % (X_test.shape[0], (y_test != y_pred).sum()))\n",
    "gnb.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a223a6ae55912484a01d987806d384ffca17e043bfd2d4dcd0949f7d6159cce0"
  },
  "kernelspec": {
   "display_name": "Python 3.10.1 64-bit (system)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
